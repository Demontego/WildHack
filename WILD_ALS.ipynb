{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08d6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import autocomplete\n",
    "from fast_autocomplete import AutoComplete\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "from pyaspeller import YandexSpeller\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import tqdm\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891ea36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8172206\n"
     ]
    }
   ],
   "source": [
    "search_history = pd.read_csv('search_history.csv')\n",
    "print(len(search_history['wbuser_id'].unique()))\n",
    "search_history = search_history.drop(search_history[search_history.cnt == 0].index)\n",
    "search_history.dropna(inplace = True)\n",
    "grouped = search_history[['wbuser_id', 'UQ']].groupby('wbuser_id', as_index=False).agg(' '.join) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c359524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = []\n",
    "for i in grouped['UQ']:\n",
    "    tmp = []\n",
    "    for j in i.split(' '):\n",
    "        if len(j) > 1:\n",
    "            tmp.append(j)\n",
    "    tmp = list(set(tmp))\n",
    "    fixed.append(' '.join(tmp))\n",
    "grouped['fixed'] = fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5309cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_popularity = pd.read_csv('query_popularity.csv')\n",
    "query_popularity.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178e3fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129358\n"
     ]
    }
   ],
   "source": [
    "queries_initial = query_popularity['query']\n",
    "dictionary = set()\n",
    "queries = []\n",
    "for query in queries_initial:\n",
    "    for word in query.split(' '):\n",
    "        if len(word)>1:\n",
    "            dictionary.add(word)\n",
    "print(len(dictionary))\n",
    "dictionary = list(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24b9072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110444\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase = False)\n",
    "vectorizer.fit_transform(dictionary)\n",
    "for i in (set.difference(set(dictionary),set(vectorizer.get_feature_names_out()))):\n",
    "    dictionary.remove(i)\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bb7ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "ans = []\n",
    "for i in range(110):\n",
    "    encoded_input = tokenizer(dictionary[i*1000:(i+1)*1000], padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = torch.squeeze(model(**encoded_input)[1])\n",
    "    ans.append(model_output)\n",
    "encoded_input = tokenizer(dictionary[110000:], padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = torch.squeeze(model(**encoded_input)[1])\n",
    "ans.append(model_output)   \n",
    "    \n",
    "queries = torch.cat(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae9c2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 336987/336987 [00:18<00:00, 18300.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import hug\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class TrieNode:\n",
    "    __slots__ = ('value', 'end_of_word', 'children', 'weight')\n",
    "\n",
    "    def __init__(self, value: str, end_of_word=False):\n",
    "        self.value = value\n",
    "        self.end_of_word = end_of_word\n",
    "        self.children = {}\n",
    "        self.weight = -1\n",
    "\n",
    "    def add(self, word_part: str, *, weight: int=-1) -> None:\n",
    "        if len(word_part) == 0:\n",
    "            self.end_of_word = True\n",
    "            self.weight = weight\n",
    "            return\n",
    "\n",
    "        first_char = word_part[0]\n",
    "        node = self.children.setdefault(first_char, TrieNode(first_char))\n",
    "        node.add(word_part[1:], weight=weight)\n",
    "\n",
    "    def find_all(self, word_part: str, path: str=\"\"):\n",
    "        if self.end_of_word:\n",
    "            yield path + self.value, self.weight\n",
    "\n",
    "        if len(word_part) > 0:\n",
    "            char = word_part[0]\n",
    "            node = self.children.get(char)\n",
    "\n",
    "            if node is not None:\n",
    "                yield from node.find_all(word_part[1:], path + self.value)\n",
    "        else:\n",
    "            for node in self.children.values():\n",
    "                yield from node.find_all(\"\", path + self.value)\n",
    "\n",
    "\n",
    "with open('words.txt',encoding=\"utf-8\") as f:\n",
    "    words = f.readlines()\n",
    "\n",
    "root = TrieNode(\"\")\n",
    "\n",
    "print('Loading words')\n",
    "for word in tqdm.tqdm(query_popularity['query']):\n",
    "    root.add(word.rstrip('\\n'), weight=1)\n",
    "\n",
    "del words\n",
    "\n",
    "\n",
    "@hug.get('/autocomplete')\n",
    "def autocomplete(string: str, hug_timer = 0):\n",
    "    split_words = string.split()\n",
    "    last_word = split_words[-1]\n",
    "    prefix = ' '.join(split_words[:-1])\n",
    "\n",
    "    suggestions = root.find_all(last_word)\n",
    "\n",
    "    full_suggestions = []\n",
    "\n",
    "    for suggestion in suggestions:\n",
    "        full_suggestions.append((\n",
    "            '{}{}'.format((prefix + ' ') if prefix else '', suggestion[0]),\n",
    "            suggestion[1],\n",
    "        ))\n",
    "\n",
    "    sorted_suggestions = sorted(\n",
    "        full_suggestions,\n",
    "        key=itemgetter(1),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'words': list(map(itemgetter(0), sorted_suggestions)),\n",
    "        'time_taken': hug_timer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8caebd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['тапочки',\n",
       " 'тапочки женские',\n",
       " 'тапочки женские домашние',\n",
       " 'тапочки женские домашние обувь',\n",
       " 'тапочки женские домашние ортопедические',\n",
       " 'тапочки женские домашние с открытыми',\n",
       " 'тапочки женские домашние с мехом',\n",
       " 'тапочки женские домашние с задником',\n",
       " 'тапочки женские домашние серые',\n",
       " 'тапочки женские домашние adanex']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocomplete('тап')['words'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd1fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "776642b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS():\n",
    "    def __init__(self,users, queries, dictionary):\n",
    "        \n",
    "        #self.queries = queries\n",
    "        self.users = users\n",
    "        self.dictionary = dictionary\n",
    "        self.FEATURE_NUM = 15\n",
    "        svd = TruncatedSVD(n_components=15, n_iter=7, random_state=42)\n",
    "        self.queries = svd.fit_transform(queries)\n",
    "        self.vectorizer = CountVectorizer(lowercase = False)\n",
    "        self.encoded_dict = self.vectorizer.fit_transform(self.dictionary)\n",
    "        self.interaction_matrix = self.vectorizer.transform(self.users['fixed'])\n",
    "        self.interaction_matrix[self.interaction_matrix>0] = 1\n",
    "        self.users_interest = sparse.random(len(self.users),self.queries.shape[1], density = 0.1)\n",
    "    \n",
    "    def implicit_als(self, a=40, it=10, l=0.1):\n",
    "        conf = self.interaction_matrix * a\n",
    "        u_s, i_s = self.interaction_matrix.shape\n",
    "        self.X = sparse.csr_matrix(np.random.normal(size=(u_s, self.FEATURE_NUM)))\n",
    "        self.Y = np.zeros((i_s, self.FEATURE_NUM))\n",
    "        for i in range(self.Y.shape[0]):\n",
    "            self.Y[i] = self.queries[i]\n",
    "        self.Y = sparse.csr_matrix(np.nan_to_num(self.Y))\n",
    "        Y_I = sparse.eye(i_s)\n",
    "        I = sparse.eye(self.FEATURE_NUM)\n",
    "        lI = l * I\n",
    "        for ip in range(it):\n",
    "            yTy = self.Y.T.dot(self.Y)\n",
    "            for u in tqdm.trange(u_s):\n",
    "                u_row = conf[u, :].toarray()\n",
    "                p_u = u_row.copy()\n",
    "                p_u[p_u != 0] = 1.0\n",
    "                CuI = sparse.diags(u_row, [0])\n",
    "                Cu = CuI + Y_I\n",
    "                yT_CuI_y = self.Y.T.dot(CuI).dot(self.Y)\n",
    "                yT_Cu_pu = self.Y.T.dot(Cu).dot(p_u.T)\n",
    "                self.X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "        return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76994655",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(grouped[0:10000],queries[:1000,:],dictionary[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2baedda1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:11<00:00, 883.08it/s]\n",
      " 30%|██████████████████████▊                                                     | 3006/10000 [00:03<00:07, 880.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12124/1755993686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicit_als\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12124/3446337255.py\u001b[0m in \u001b[0;36mimplicit_als\u001b[1;34m(self, a, it, l)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mCu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCuI\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mY_I\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0myT_CuI_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCuI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[0myT_Cu_pu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_u\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspsolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTy\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0myT_CuI_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myT_Cu_pu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\techno_w\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \"\"\"\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\techno_w\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    467\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\techno_w\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;31m# csr_matvec or csc_matvec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "als.implicit_als()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167eb402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
