{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ef2da2",
   "metadata": {},
   "source": [
    "# Основа модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "from pyaspeller import YandexSpeller\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import tqdm\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy import spatial\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316f0a5",
   "metadata": {},
   "source": [
    "## Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "891ea36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8172206\n"
     ]
    }
   ],
   "source": [
    "search_history = pd.read_csv('search_history.csv')\n",
    "print(len(search_history['wbuser_id'].unique()))\n",
    "search_history = search_history.drop(search_history[search_history.cnt == 0].index)\n",
    "search_history.dropna(inplace = True)\n",
    "grouped = search_history[['wbuser_id', 'UQ']].groupby('wbuser_id', as_index=False).agg(' '.join) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9af0306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wbuser_id</th>\n",
       "      <th>UQ</th>\n",
       "      <th>cnt</th>\n",
       "      <th>locale</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37bc0ce12ffabce1b1882e66d461ed0e</td>\n",
       "      <td>тапочки женские домашние</td>\n",
       "      <td>1933</td>\n",
       "      <td>Ru</td>\n",
       "      <td>0</td>\n",
       "      <td>10:48:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4636a6706e6736d818816d8657565aa2</td>\n",
       "      <td>чехол для бейджика</td>\n",
       "      <td>1513</td>\n",
       "      <td>Ru</td>\n",
       "      <td>0</td>\n",
       "      <td>10:48:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>708f4040baf99acfc9496563edff1b1a</td>\n",
       "      <td>GUESS</td>\n",
       "      <td>4</td>\n",
       "      <td>Ru</td>\n",
       "      <td>0</td>\n",
       "      <td>10:48:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70311ec9008a31f743c164e6f1198c86</td>\n",
       "      <td>фототфон</td>\n",
       "      <td>92272</td>\n",
       "      <td>Ru</td>\n",
       "      <td>0</td>\n",
       "      <td>10:48:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3d5e0b035ee04de0801692081278ef1a</td>\n",
       "      <td>7024</td>\n",
       "      <td>93</td>\n",
       "      <td>Ru</td>\n",
       "      <td>0</td>\n",
       "      <td>10:48:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83919232</th>\n",
       "      <td>8b939f9c7b2c24003477d4408ce908fa</td>\n",
       "      <td>термос для еды</td>\n",
       "      <td>6996</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>23:30:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83919233</th>\n",
       "      <td>70311ec9008a31f743c164e6f1198c86</td>\n",
       "      <td>фаллоимитатор вибратор</td>\n",
       "      <td>3288</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>23:30:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83919235</th>\n",
       "      <td>c0d75daa762272829028e43a62ff7c75</td>\n",
       "      <td>весы кухонные электронные</td>\n",
       "      <td>1407</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>23:30:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83919236</th>\n",
       "      <td>70311ec9008a31f743c164e6f1198c86</td>\n",
       "      <td>термобелье мужское</td>\n",
       "      <td>3233</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>23:30:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83919237</th>\n",
       "      <td>ab988d1855d8b5c260380e942ab8e572</td>\n",
       "      <td>рубашка</td>\n",
       "      <td>56396</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>23:30:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64926354 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 wbuser_id                         UQ    cnt  \\\n",
       "0         37bc0ce12ffabce1b1882e66d461ed0e   тапочки женские домашние   1933   \n",
       "1         4636a6706e6736d818816d8657565aa2         чехол для бейджика   1513   \n",
       "2         708f4040baf99acfc9496563edff1b1a                      GUESS      4   \n",
       "4         70311ec9008a31f743c164e6f1198c86                   фототфон  92272   \n",
       "5         3d5e0b035ee04de0801692081278ef1a                       7024     93   \n",
       "...                                    ...                        ...    ...   \n",
       "83919232  8b939f9c7b2c24003477d4408ce908fa             термос для еды   6996   \n",
       "83919233  70311ec9008a31f743c164e6f1198c86     фаллоимитатор вибратор   3288   \n",
       "83919235  c0d75daa762272829028e43a62ff7c75  весы кухонные электронные   1407   \n",
       "83919236  70311ec9008a31f743c164e6f1198c86         термобелье мужское   3233   \n",
       "83919237  ab988d1855d8b5c260380e942ab8e572                    рубашка  56396   \n",
       "\n",
       "         locale  weekday      time  \n",
       "0            Ru        0  10:48:53  \n",
       "1            Ru        0  10:48:53  \n",
       "2            Ru        0  10:48:53  \n",
       "4            Ru        0  10:48:53  \n",
       "5            Ru        0  10:48:53  \n",
       "...         ...      ...       ...  \n",
       "83919232     Ru        6  23:30:40  \n",
       "83919233     Ru        6  23:30:40  \n",
       "83919235     Ru        6  23:30:40  \n",
       "83919236     Ru        6  23:30:40  \n",
       "83919237     Ru        6  23:30:40  \n",
       "\n",
       "[64926354 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = []\n",
    "for i in grouped['UQ']:\n",
    "    tmp = []\n",
    "    for j in i.split(' '):\n",
    "        if len(j) > 1:\n",
    "            tmp.append(j)\n",
    "    tmp = list(set(tmp))\n",
    "    fixed.append(' '.join(tmp))\n",
    "grouped['fixed'] = fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5309cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_popularity = pd.read_csv('query_popularity.csv')\n",
    "query_popularity.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178e3fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129358\n"
     ]
    }
   ],
   "source": [
    "queries_initial = query_popularity['query']\n",
    "dictionary = set()\n",
    "queries = []\n",
    "for query in queries_initial:\n",
    "    for word in query.split(' '):\n",
    "        if len(word)>1:\n",
    "            dictionary.add(word)\n",
    "print(len(dictionary))\n",
    "dictionary = list(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d24b9072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110444\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase = False)\n",
    "vectorizer.fit_transform(dictionary)\n",
    "for i in (set.difference(set(dictionary),set(vectorizer.get_feature_names()))):\n",
    "    dictionary.remove(i)\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "ans = []\n",
    "for i in range(110):\n",
    "    encoded_input = tokenizer(dictionary[i*1000:(i+1)*1000], padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = torch.squeeze(model(**encoded_input)[1])\n",
    "    ans.append(model_output)\n",
    "encoded_input = tokenizer(dictionary[110000:], padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = torch.squeeze(model(**encoded_input)[1])\n",
    "ans.append(model_output)   \n",
    "    \n",
    "queries = torch.cat(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141b95b",
   "metadata": {},
   "source": [
    "## Код модели и ее инициализация, работает долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    __slots__ = ('value', 'end_of_word', 'children', 'weight')\n",
    "\n",
    "    def __init__(self, value: str, end_of_word=False):\n",
    "        self.value = value\n",
    "        self.end_of_word = end_of_word\n",
    "        self.children = {}\n",
    "        self.weight = -1\n",
    "\n",
    "    def add(self, word_part: str, *, weight: int=-1) -> None:\n",
    "        if len(word_part) == 0:\n",
    "            self.end_of_word = True\n",
    "            self.weight = weight\n",
    "            return\n",
    "\n",
    "        first_char = word_part[0]\n",
    "        node = self.children.setdefault(first_char, TrieNode(first_char))\n",
    "        node.add(word_part[1:], weight=weight)\n",
    "\n",
    "    def find_all(self, word_part: str, path: str=\"\"):\n",
    "        if self.end_of_word:\n",
    "            yield path + self.value, self.weight\n",
    "\n",
    "        if len(word_part) > 0:\n",
    "            char = word_part[0]\n",
    "            node = self.children.get(char)\n",
    "\n",
    "            if node is not None:\n",
    "                yield from node.find_all(word_part[1:], path + self.value)\n",
    "        else:\n",
    "            for node in self.children.values():\n",
    "                yield from node.find_all(\"\", path + self.value)\n",
    "                \n",
    "    def autocomplete(self, string):\n",
    "        split_words = string.split()\n",
    "        last_word = split_words[-1]\n",
    "        prefix = ' '.join(split_words[:-1])\n",
    "\n",
    "        suggestions = self.find_all(last_word)\n",
    "\n",
    "        full_suggestions = []\n",
    "\n",
    "        for suggestion in suggestions:\n",
    "            full_suggestions.append((\n",
    "                '{}{}'.format((prefix + ' ') if prefix else '', suggestion[0]),\n",
    "                suggestion[1],\n",
    "            ))\n",
    "\n",
    "        sorted_suggestions = sorted(\n",
    "            full_suggestions,\n",
    "            key=itemgetter(1),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'words': list(map(itemgetter(0), sorted_suggestions))\n",
    "        }\n",
    "\n",
    "root = TrieNode(\"\")\n",
    "\n",
    "for word in tqdm.tqdm(query_popularity['query']):\n",
    "    root.add(word.rstrip('\\n'), weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776642b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS():\n",
    "    def __init__(self,users, queries, dictionary, trie):\n",
    "        \n",
    "        #self.queries = queries\n",
    "        #self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "        self.trie = trie\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "        self.model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")  \n",
    "        self.users = users\n",
    "        self.dictionary = dictionary\n",
    "        self.FEATURE_NUM = 15\n",
    "        self.svd = TruncatedSVD(n_components=15, n_iter=7, random_state=42)\n",
    "        self.queries = self.svd.fit_transform(queries)\n",
    "        self.vectorizer = CountVectorizer(lowercase = False)\n",
    "        self.encoded_dict = self.vectorizer.fit_transform(self.dictionary)\n",
    "        self.interaction_matrix = self.vectorizer.transform(self.users['fixed'])\n",
    "        self.interaction_matrix[self.interaction_matrix>0] = 1\n",
    "        self.users_interest = sparse.random(len(self.users),self.queries.shape[1], density = 0.1)\n",
    "    \n",
    "    def implicit_als(self, a=40, it=10, l=0.1):\n",
    "        conf = self.interaction_matrix * a\n",
    "        u_s, i_s = self.interaction_matrix.shape\n",
    "        self.X = sparse.csr_matrix(np.random.normal(size=(u_s, self.FEATURE_NUM)))\n",
    "        self.Y = np.zeros((i_s, self.FEATURE_NUM)) \n",
    "        for i in range(self.Y.shape[0]):\n",
    "            self.Y[i] = self.queries[i]\n",
    "        self.Y = sparse.csr_matrix(np.nan_to_num(self.Y))\n",
    "        Y_I = sparse.eye(i_s)\n",
    "        I = sparse.eye(self.FEATURE_NUM)\n",
    "        lI = l * I\n",
    "        yTy = self.Y.T.dot(self.Y)\n",
    "        for u in tqdm.trange(u_s):\n",
    "            u_row = conf[u, :].toarray()\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "            yT_CuI_y = self.Y.T.dot(CuI).dot(self.Y)\n",
    "            yT_Cu_pu = self.Y.T.dot(Cu).dot(p_u.T)\n",
    "            for ip in range(it):\n",
    "                self.X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "        return\n",
    "    def predict(self, prefix, idx):\n",
    "        self.current_user = self.X[idx]\n",
    "        lenter = len(prefix.split(' '))\n",
    "        results = set([x.split(' ')[lenter - 1] for x in self.trie.autocomplete(prefix)['words']])\n",
    "        self.bert_interpretation = self.tokenizer(list(results), padding=True, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = torch.squeeze(self.model(**self.bert_interpretation)[1])\n",
    "        self.bert_interpretation = self.svd.transform(model_output)\n",
    "        distance = {}\n",
    "        for vec, dec in zip(self.bert_interpretation,results) :\n",
    "            distance[dec] = spatial.distance.cosine(vec, self.current_user.toarray())\n",
    "        sort_sug = sorted(distance.items(), key=lambda x: x[1])[:10]\n",
    "        return [x[0] for x in sort_sug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76994655",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(grouped[:10000],queries,dictionary, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4211f",
   "metadata": {},
   "source": [
    "## Обучение модельки... вообще быстро, но если увеличивать it, то долговато"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baedda1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "als.implicit_als(it=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537d4e9",
   "metadata": {},
   "source": [
    "## Сохранение всей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdca7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(als, 'wildals_10000.jbl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493413d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4703a29",
   "metadata": {},
   "source": [
    "## Загрузка модели и инференс, Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a400340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "from pyaspeller import YandexSpeller\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import tqdm\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy import spatial\n",
    "from operator import itemgetter\n",
    "\n",
    "class TrieNode:\n",
    "    __slots__ = ('value', 'end_of_word', 'children', 'weight')\n",
    "\n",
    "    def __init__(self, value: str, end_of_word=False):\n",
    "        self.value = value\n",
    "        self.end_of_word = end_of_word\n",
    "        self.children = {}\n",
    "        self.weight = -1\n",
    "\n",
    "    def add(self, word_part: str, *, weight: int=-1) -> None:\n",
    "        if len(word_part) == 0:\n",
    "            self.end_of_word = True\n",
    "            self.weight = weight\n",
    "            return\n",
    "\n",
    "        first_char = word_part[0]\n",
    "        node = self.children.setdefault(first_char, TrieNode(first_char))\n",
    "        node.add(word_part[1:], weight=weight)\n",
    "\n",
    "    def find_all(self, word_part: str, path: str=\"\"):\n",
    "        if self.end_of_word:\n",
    "            yield path + self.value, self.weight\n",
    "\n",
    "        if len(word_part) > 0:\n",
    "            char = word_part[0]\n",
    "            node = self.children.get(char)\n",
    "\n",
    "            if node is not None:\n",
    "                yield from node.find_all(word_part[1:], path + self.value)\n",
    "        else:\n",
    "            for node in self.children.values():\n",
    "                yield from node.find_all(\"\", path + self.value)\n",
    "                \n",
    "    def autocomplete(self, string):\n",
    "        split_words = string.split()\n",
    "        last_word = split_words[-1]\n",
    "        prefix = ' '.join(split_words[:-1])\n",
    "\n",
    "        suggestions = self.find_all(last_word)\n",
    "\n",
    "        full_suggestions = []\n",
    "\n",
    "        for suggestion in suggestions:\n",
    "            full_suggestions.append((\n",
    "                '{}{}'.format((prefix + ' ') if prefix else '', suggestion[0]),\n",
    "                suggestion[1],\n",
    "            ))\n",
    "\n",
    "        sorted_suggestions = sorted(\n",
    "            full_suggestions,\n",
    "            key=itemgetter(1),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'words': list(map(itemgetter(0), sorted_suggestions))\n",
    "        }\n",
    "\n",
    "class ALS():\n",
    "    def __init__(self,users, queries, dictionary, trie):\n",
    "        \n",
    "        #self.queries = queries\n",
    "        #self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "        self.trie = trie\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "        self.model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")  \n",
    "        self.users = users\n",
    "        self.dictionary = dictionary\n",
    "        self.FEATURE_NUM = 15\n",
    "        self.svd = TruncatedSVD(n_components=15, n_iter=7, random_state=42)\n",
    "        self.queries = self.svd.fit_transform(queries)\n",
    "        self.vectorizer = CountVectorizer(lowercase = False)\n",
    "        self.encoded_dict = self.vectorizer.fit_transform(self.dictionary)\n",
    "        self.interaction_matrix = self.vectorizer.transform(self.users['fixed'])\n",
    "        self.interaction_matrix[self.interaction_matrix>0] = 1\n",
    "        self.users_interest = sparse.random(len(self.users),self.queries.shape[1], density = 0.1)\n",
    "    \n",
    "    def implicit_als(self, a=40, it=10, l=0.1):\n",
    "        conf = self.interaction_matrix * a\n",
    "        u_s, i_s = self.interaction_matrix.shape\n",
    "        self.X = sparse.csr_matrix(np.random.normal(size=(u_s, self.FEATURE_NUM)))\n",
    "        self.Y = np.zeros((i_s, self.FEATURE_NUM)) \n",
    "        for i in range(self.Y.shape[0]):\n",
    "            self.Y[i] = self.queries[i]\n",
    "        self.Y = sparse.csr_matrix(np.nan_to_num(self.Y))\n",
    "        Y_I = sparse.eye(i_s)\n",
    "        I = sparse.eye(self.FEATURE_NUM)\n",
    "        lI = l * I\n",
    "        yTy = self.Y.T.dot(self.Y)\n",
    "        for u in tqdm.trange(u_s):\n",
    "            u_row = conf[u, :].toarray()\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "            yT_CuI_y = self.Y.T.dot(CuI).dot(self.Y)\n",
    "            yT_Cu_pu = self.Y.T.dot(Cu).dot(p_u.T)\n",
    "            for ip in range(it):\n",
    "                self.X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "        return\n",
    "    def predict(self, prefix, idx):\n",
    "        self.current_user = self.X[idx]\n",
    "        lenter = len(prefix.split(' '))\n",
    "        results = set([x.split(' ')[lenter - 1] for x in self.trie.autocomplete(prefix)['words']])\n",
    "        self.bert_interpretation = self.tokenizer(list(results), padding=True, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = torch.squeeze(self.model(**self.bert_interpretation)[1])\n",
    "        self.bert_interpretation = self.svd.transform(model_output)\n",
    "        distance = {}\n",
    "        for vec, dec in zip(self.bert_interpretation,results) :\n",
    "            distance[dec] = spatial.distance.cosine(vec, self.current_user.toarray())\n",
    "        sort_sug = sorted(distance.items(), key=lambda x: x[1])[:10]\n",
    "        return [x[0] for x in sort_sug]\n",
    "\n",
    "\n",
    "als = joblib.load('wildals_10000.jbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aeb118b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['сапфир',\n",
       " 'сапфирин',\n",
       " 'сапропель',\n",
       " 'сапковский',\n",
       " 'сапгир',\n",
       " 'сапольски',\n",
       " 'сапсан',\n",
       " 'сапоги',\n",
       " 'сапоки',\n",
       " 'сапожки']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prefix = 'сап'\n",
    "iid = 125\n",
    "\n",
    "als.predict(prefix, iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "511cebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001d2da396e9514a77ccfec8182cb0\n",
      "Wall time: 22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['сапоки',\n",
       " 'сапольски',\n",
       " 'сапоги',\n",
       " 'сапфир',\n",
       " 'сапои',\n",
       " 'сапрги',\n",
       " 'сапожки',\n",
       " 'сапфирин',\n",
       " 'с',\n",
       " 'сапаги']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prefix = 'сап'\n",
    "iid = 12\n",
    "print(als.users.loc[iid].wbuser_id)\n",
    "als.predict(prefix, iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4932443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wbuser_id</th>\n",
       "      <th>UQ</th>\n",
       "      <th>cnt</th>\n",
       "      <th>locale</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21524176</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>сникерсы женские</td>\n",
       "      <td>625</td>\n",
       "      <td>Ru</td>\n",
       "      <td>1</td>\n",
       "      <td>19:38:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21692711</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>сникерсы женские</td>\n",
       "      <td>625</td>\n",
       "      <td>Ru</td>\n",
       "      <td>1</td>\n",
       "      <td>19:40:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21700937</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>сникерсы женские</td>\n",
       "      <td>625</td>\n",
       "      <td>Ru</td>\n",
       "      <td>1</td>\n",
       "      <td>19:40:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21904578</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>сникерсы женские</td>\n",
       "      <td>625</td>\n",
       "      <td>Ru</td>\n",
       "      <td>1</td>\n",
       "      <td>19:42:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22024524</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>сникерсы женские</td>\n",
       "      <td>625</td>\n",
       "      <td>Ru</td>\n",
       "      <td>1</td>\n",
       "      <td>19:44:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55323944</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>ни сы книга</td>\n",
       "      <td>63</td>\n",
       "      <td>Ru</td>\n",
       "      <td>4</td>\n",
       "      <td>14:37:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77075043</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>костюм брюки и рубашка</td>\n",
       "      <td>10092</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>16:39:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81946063</th>\n",
       "      <td>00001d2da396e9514a77ccfec8182cb0</td>\n",
       "      <td>костюм брюки и рубашка</td>\n",
       "      <td>10092</td>\n",
       "      <td>Ru</td>\n",
       "      <td>6</td>\n",
       "      <td>18:52:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 wbuser_id                      UQ    cnt  \\\n",
       "21524176  00001d2da396e9514a77ccfec8182cb0        сникерсы женские    625   \n",
       "21692711  00001d2da396e9514a77ccfec8182cb0        сникерсы женские    625   \n",
       "21700937  00001d2da396e9514a77ccfec8182cb0        сникерсы женские    625   \n",
       "21904578  00001d2da396e9514a77ccfec8182cb0        сникерсы женские    625   \n",
       "22024524  00001d2da396e9514a77ccfec8182cb0        сникерсы женские    625   \n",
       "55323944  00001d2da396e9514a77ccfec8182cb0             ни сы книга     63   \n",
       "77075043  00001d2da396e9514a77ccfec8182cb0  костюм брюки и рубашка  10092   \n",
       "81946063  00001d2da396e9514a77ccfec8182cb0  костюм брюки и рубашка  10092   \n",
       "\n",
       "         locale  weekday      time  \n",
       "21524176     Ru        1  19:38:39  \n",
       "21692711     Ru        1  19:40:37  \n",
       "21700937     Ru        1  19:40:42  \n",
       "21904578     Ru        1  19:42:55  \n",
       "22024524     Ru        1  19:44:09  \n",
       "55323944     Ru        4  14:37:08  \n",
       "77075043     Ru        6  16:39:16  \n",
       "81946063     Ru        6  18:52:51  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_history[search_history.wbuser_id=='00001d2da396e9514a77ccfec8182cb0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c07bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
